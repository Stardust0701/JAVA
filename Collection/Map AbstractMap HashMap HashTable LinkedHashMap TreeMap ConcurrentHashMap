1.	Map.hashCode：所有的entry的hashCode的和，entry.hashCode为key.hashCode^value.hashCode
2.	调用get方法和put等方法时，先用hash（key）来计算hash值，公式为h = (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16)；然后通过index = (tab.length - 1) & h来定位
3.	HashMap初始容量为16，最大容量为2的30次方，负载因子默认为0.75，临界值threshold为桶数组长度乘以负载因子，桶数组长度为通过tableSizeFor方法计算出大于指定值的最小2次方的数，每次扩容都将容量乘以二，最大为Integer.MAX_VALUE
4.	当hashMap.size大于threshold临界值时，触发resize扩容
5.	当new一个hashMap的时候，并没有给数组分配空间（也就是初始化数组），在第一次put数据时，初始化数组
6.	HashMap用Node<K,V>[] table存放entry（Node继承自entry），当key的hash相同时，采用拉链法解决冲突，添加时，当桶中链表长度大于等于8时，转为红黑树数据结构（table的长度需要大于等于64，否则进行resize操作）；删除扩容时，若桶中为红黑树数据结构，则当树中元素个数小于等于6时，会将红黑树数据结构转为链表
7.	 
8.	问题：红黑树的添加删除平衡等方法？
9.	hashTable类与hashMap的区别：
（1）hashTable在new对象的时候就初始化数组，而hashMap是在第一次put数据的时候初始化数组；
（2）hashTable中key和value不能为null，而hashMap中可以（key只能有一个为null，而value则可以有多个为null）
（3）hashTable默认容量为11，默认负载因子为0.75，扩容时，将容量乘以二再加一
（4）hashTable中get和put时直接用key.hashCode作为hash值，然后进行定位，公式为(key.hashCode& 0x7FFFFFFF) % tab.length，和0x7FFFFFFF进行与操作是为了得到正数
（5）hashTable线程安全，而hashMap线程不安全
10.	linkedHashMap类与HashMap区别：
（1）LinkedHashMap是HashMap的子类。它继承了HashMap，仅重写了几个方法，以改变它迭代遍历时的顺序。这也是其与HashMap相比最大的不同。 
    （2）在每次插入数据，或者访问、修改数据时，会增加节点、或调整链表的节点顺序。以决定迭代时输出的顺序。
（3）accessOrder ,默认是false，则迭代时输出的顺序是插入节点的顺序。若为true，则输出的顺序是按照访问节点的顺序。为true时，可以在这基础之上构建一个LruCache.
（4）LinkedHashMap并没有重写任何put方法。但是其重写了构建新节点的newNode()方法.在每次构建新节点时，将新节点链接在内部双向链表的尾部
（5）accessOrder=true的模式下,在afterNodeAccess()函数中，会将当前被访问到的节点e，移动至内部的双向链表的尾部。值得注意的是，afterNodeAccess()函数中，会修改modCount,因此当你正在accessOrder=true的模式下,迭代LinkedHashMap时，如果同时查询访问数据，也会导致fail-fast，因为迭代的顺序已经改变。
（6）nextNode() 就是迭代器里的next()方法 。 该方法的实现可以看出，迭代LinkedHashMap，就是从内部维护的双链表的表头开始循环输出。 而双链表节点的顺序在LinkedHashMap的增、删、改、查时都会更新。以满足按照插入顺序输出，还是访问顺序输出。
（7）它与HashMap比，重写了containsValue()方法，直接遍历内部链表去比对value值是否相等。
11.	treeMap与hashMap区别：
（1）treeMap实现sortMap接口，基于红黑树，而hashMap基于哈希散列表
（2）treeMap默认按键的升序排列
（3）treeMap的key和value都不能为null
（4）treeMap遍历是有序的
12.	ConcurrentHashMap类
（1）JDK1.8中concurrentHashMap的实现已经摒弃了Segment（分段锁）的概念，而是直接用Node数组+链表+红黑树的数据结构来实现，并发控制使用Synchronized和CAS来操作，整个看起来就像是优化过且线程安全的HashMap，虽然在JDK1.8中还能看到Segment的数据结构，但是已经简化了属性，只是为了兼容旧版本
（2）初始化默认值等与hashMap一致
（3）Node内部类只允许对数据进行查找，不允许进行修改
（4）TreeBin内部类并不负责包装用户的key、value信息，而是包装的很多TreeNode节点。它代替了TreeNode的根节点，也就是说在实际的ConcurrentHashMap“数组”中，存放的是TreeBin对象，而不是TreeNode对象，这是与HashMap的区别，并且该类还带有了读写锁。
（5）put操作过程，对当前的table进行无条件自循环直到put成功，可以分成以下六步流程来概述：
1>如果没有初始化就先调用initTable（）方法来进行初始化过程
2>如果没有hash冲突就直接CAS插入
3>如果还在进行扩容操作就先进行扩容
4>如果存在hash冲突，就加锁来保证线程安全，这里有两种情况，一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入，
5>最后一步如果该链表的数量大于阈值8，就要先转换成黑红树的结构，break再一次进入循环
6>如果添加成功就调用addCount（）方法统计size，并且检查是否需要扩容
（6）get的操作流程可以分为三个步骤来描述
1>计算hash值，定位到该table索引位置，如果是首节点符合就返回
2>如果遇到扩容的时候，会调用标志正在扩容节点ForwardingNode的find方法，查找该节点，匹配就返回
3>以上都不符合的话，就往下遍历节点，匹配就返回，否则最后就返回null
（7）计算hash时，先将key.hashCode做处理h = (h ^ (h >>> 16)) & 0x7fffffff，然后通过index = (table.length - 1) & h进行定位
